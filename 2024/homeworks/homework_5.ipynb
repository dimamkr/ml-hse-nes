{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 5"
      ],
      "metadata": {
        "id": "13w_xQq-zCs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По курсу \"Машинное обучение\"\n",
        "\n",
        "**Аннотация:**\n",
        "\n",
        "В этом задании вам нужно решить несколько задач по ансамблям моделей."
      ],
      "metadata": {
        "id": "6uu_4bHBzHD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1 (2 балла)\n",
        "\n",
        "Рассмотрим модель логистической регрессии с функцией потерь:\n",
        "\n",
        "\\begin{equation}\n",
        "    L = - \\frac{1}{n} \\sum_{i=1}^{n} y_i \\log \\hat{y}_{i} + (1-y_i) \\log (1 - \\hat{y}_{i}),\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "    \\hat{y}_{i} = \\sigma(z_i),\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "    z_{i} = x_i^{T}w.\n",
        "\\end{equation}\n",
        "\n",
        "где $n$ - количество объектов в выборке; $\\hat{y}_{i}$ - прогноз модели; $w$ - веса модели; Покажите, что градиент вычисляется по формуле:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\frac{\\partial L}{\\partial w} = - \\frac{1}{n} \\sum_{i=1}^{n} x_i (y_i - \\hat{y}_{i}).\n",
        "\\end{equation}\n",
        "\n",
        "Как это выражение будет выглядеть в матричной форме?\n"
      ],
      "metadata": {
        "id": "_d0VkEn0zNgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение:** #Ваше решение здесь"
      ],
      "metadata": {
        "id": "NRhfUq38zQgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 2 (2 балла)\n",
        "\n",
        "Рассмотрим задачу регрессии, где нам нужно предсказать значение функции $f(x)$, где $x$ - одномерная непрерывная переменная. Пусть у нас есть $M$ моделей регрессии, которые были обучены на случайно сгенерированных наборах данных. Прогноз каждой модели $\\hat{y}_{m} (x)$ можем записать так:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\hat{y}_{m} (x) = f(x) + \\epsilon_m(x),\n",
        "\\end{equation}\n",
        "\n",
        "где $\\epsilon_m(x)$ - случайная величина со стандартным нормальным распределением $\\mathcal{N}(\\mu=0, \\sigma=1)$. Рассмотрим модель бэггинга:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\hat{y}_{bag} (x) = \\frac{1}{M} \\sum_{m=1}^{M} \\hat{y}_{m} (x).\n",
        "\\end{equation}\n",
        "\n",
        "Обозначим среднюю ошибку всех моделей следующим образом:\n",
        "\n",
        "\\begin{equation}\n",
        "    E_{av} = \\frac{1}{M} \\sum_{m=1}^{M} E[(\\hat{y}_{m}(x) - f(x))^2].\n",
        "\\end{equation}\n",
        "\n",
        "Обозначим среднюю ошибку модели бэггинга так:\n",
        "\n",
        "\\begin{equation}\n",
        "    E_{bag} = E[(\\hat{y}_{bag}(x) - f(x))^2].\n",
        "\\end{equation}\n",
        "\n",
        "Покажите, что\n",
        "\n",
        "\\begin{equation}\n",
        "    E_{bag} = \\frac{1}{M} E_{av}.\n",
        "\\end{equation}\n",
        "\n",
        "Ошибки $\\epsilon_m(x)$ считайте независимыми."
      ],
      "metadata": {
        "id": "s-bnKY4uzapO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение:** #Ваше решение здесь"
      ],
      "metadata": {
        "id": "y_aaDimazUv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 3 (2 балла)\n",
        "\n",
        "Используя неравенство Йенсена покажите, что $E_{bag} \\le E_{av}$ для любой выпуклой функции потерь, а не только для MSE."
      ],
      "metadata": {
        "id": "7Qrfkk3SzfrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение:** #Ваше решение здесь"
      ],
      "metadata": {
        "id": "tjwinmm6zVLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 4 (2 балла)\n",
        "\n",
        "Рассмотрим алгоритм градиентного бустинга на решающих деревьях для задачи классификации с логистической функцией потерь:\n",
        "\n",
        "\\begin{equation}\n",
        "    L(y, \\hat{y}_{k} (x)) = - \\frac{1}{n} \\sum_{i=1}^{n} y_i \\log \\hat{y}_{k} (x_i) + (1-y_i) \\log (1 - \\hat{y}_{k} (x_i)),\n",
        "\\end{equation}\n",
        "\n",
        "где $n$ - количество объектов в выборке; $\\hat{y}_{k} (x_i)$ - прогноз ансамбля из $k$ деревьев. Покажите, что остатки (сдвиги) $s$ вычисляются по формуле:\n",
        "\n",
        "\\begin{equation}\n",
        "    s(x_i) = \\frac{y_i - \\hat{y}_{k} (x_i)}{\\hat{y}_{k} (x_i)(1- \\hat{y}_{k} (x_i))}.\n",
        "\\end{equation}\n",
        "\n",
        "Что дальше нужно делать с этими остатками? Опишите остальные шаги алгоритма построения градиентного бустинга. Какую функцию потерь нужно использовать для обучения новго дерева в бустинге?\n"
      ],
      "metadata": {
        "id": "bl_daCpnzlIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение:** #Ваше решение здесь"
      ],
      "metadata": {
        "id": "0LtKXHkHzVg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 5 (2 балла)\n",
        "\n",
        "Рассмотрим выборку из $n$ объектов, где $n$ достаточно большое. Будем использовать метод бутстрапа для сэмплирования подвыборок из n объектов с повторениями. Покажите, что каждая подвыборка содержит в среднем 63\\% объектов исходной выборки."
      ],
      "metadata": {
        "id": "L8hdeuuXzog-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение:** #Ваше решение здесь"
      ],
      "metadata": {
        "id": "Ry6Ahy1izX36"
      }
    }
  ]
}