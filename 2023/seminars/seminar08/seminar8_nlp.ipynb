{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsM0a256xtFF"
   },
   "source": [
    "# Seminar 8. Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKfdpPXXxtFK"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rgkinkm5xtFN"
   },
   "source": [
    "# Sentiment Analysis in Russian\n",
    "(from https://www.kaggle.com/c/sentiment-analysis-in-russian/data)\n",
    "\n",
    "The goal is to estimate sentiment of news in russian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgjCfXNixtFN"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agU-x45OxtFO",
    "outputId": "52a380a7-4214-40ab-c9f1-138b5a4762e3"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hushchyn-mikhail/hse_se_ml/s08/2020/s08-nlp/Data/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btCX4hJ1xtFP"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# with open('Data/train.json') as json_file:\n",
    "with open('train.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KX2KxRebxtFQ",
    "outputId": "4b0083a8-93ed-47e8-940b-3a7313953f54"
   },
   "outputs": [],
   "source": [
    "# Show example\n",
    "num = 1 # 100 - pos\n",
    "\n",
    "print(\"ID: \",          data[num][\"id\"], \"\\n\")\n",
    "print(\"Text: \\n\",      data[num][\"text\"])\n",
    "print(\"Sentiment: \",   data[num][\"sentiment\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wC2bjk8xtFQ"
   },
   "source": [
    "## Tokenization and data cleaning\n",
    "\n",
    "Let's split each text into words (**tokenizations**) and remove all **stop words** and punctuation characters. **Stop words** are words that commonly used in texts and can be ignored losing the texts meaning.\n",
    "\n",
    "<center><img src=\"https://github.com/shestakoff/hse_se_ml/blob/master/2020/s08-nlp/img/tokenization.png?raw=1\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJ9pXGxTxtFR"
   },
   "outputs": [],
   "source": [
    "import string # for work with strings\n",
    "import nltk   # Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCs9lyYLxtFR",
    "outputId": "59f578d5-3d33-4338-c2b8-f855d2dd63cc"
   },
   "outputs": [],
   "source": [
    "# get russian stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "# example of stop words\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MZsOeSIRxtFS",
    "outputId": "cee34e84-8fdd-40a4-d204-1be2060c2bc2"
   },
   "outputs": [],
   "source": [
    "# punctuation characters\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiI8nHYtxtFU"
   },
   "outputs": [],
   "source": [
    "# define word tokenizer\n",
    "word_tokenizer = nltk.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRE068i_xtFU"
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    texts = []\n",
    "    targets = []\n",
    "\n",
    "    for item in data:\n",
    "\n",
    "        # collect nlabels of news\n",
    "        if item['sentiment'] == 'negative':\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            targets.append(1)\n",
    "\n",
    "        text_lower = item['text'].lower() # convert words in a text to lower case\n",
    "        tokens     = word_tokenizer.tokenize(text_lower) # splits the text into tokens (words)\n",
    "\n",
    "        # remove punct and stop words from tokens\n",
    "        tokens = [word for word in tokens if (word not in string.punctuation and word not in stop_words)]\n",
    "\n",
    "        texts.append(tokens) # collect the text tokens\n",
    "\n",
    "    return texts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMGjfD-DxtFV"
   },
   "outputs": [],
   "source": [
    "# run tokenization and data cleaning\n",
    "texts, y = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPuzXEeuxtFV",
    "outputId": "08262aca-78b9-4451-8d7b-bf1a8a4db1d4"
   },
   "outputs": [],
   "source": [
    "# example\n",
    "i = 1\n",
    "print(\"Label: \", y[i])\n",
    "print(\"Tokens: \", texts[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTe7rPjgxtFW"
   },
   "source": [
    "## Words normalization\n",
    "\n",
    "Here we will consider 2 ways of words normalizing: **stemming** and **lemmatization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzGckc5RxtFW"
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zsUCzmNxtFX"
   },
   "source": [
    "<center><img src=\"https://github.com/shestakoff/hse_se_ml/blob/master/2020/s08-nlp/img/stem2.svg?raw=1\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G67Nf77bxtFX"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# define stemmer\n",
    "stemmer = SnowballStemmer(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pzv2hpZxtFX",
    "outputId": "bc9605fe-3ee7-47a1-e059-01a25aa9e90c"
   },
   "outputs": [],
   "source": [
    "# example of its work\n",
    "i = 1\n",
    "for aword in texts[i][:10]:\n",
    "    aword_stem = stemmer.stem(aword)\n",
    "    print(\"Before: %s, After: %s\" % (aword, aword_stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmGHjbyqxtFY"
   },
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization convert a word to its normal form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqUL-S-1xtFY"
   },
   "source": [
    "<center><img src=\"https://github.com/shestakoff/hse_se_ml/blob/master/2020/s08-nlp/img/lemm.png?raw=1\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9KGE_vfxtFY",
    "outputId": "04ad20f0-3926-4c4d-b792-47428a50fd19"
   },
   "outputs": [],
   "source": [
    "# ! pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awGp_K9HxtFZ"
   },
   "outputs": [],
   "source": [
    "import pymorphy2 # Морфологический анализатор\n",
    "\n",
    "# define lemmatizer :)\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OaJcyjSxtFZ",
    "outputId": "404c588c-ca63-4c93-a9c3-193aa94d3d72"
   },
   "outputs": [],
   "source": [
    "# example of its work\n",
    "i = 1\n",
    "for aword in texts[i][:10]:\n",
    "    aword_norm = morph.parse(aword)[0].normal_form\n",
    "    print(\"Before: %s, After: %s\" % (aword, aword_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10514SjRxtFa"
   },
   "source": [
    "Oscar goes to stemming!\n",
    "\n",
    "Stemming oscar speach:  Thanks to the academy for this prestigious award! I would like to thank all nlp developers that are lazy to use lematization and do not want to wait for too long. Thank you, thank you very much!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "8c08bdd1764241f5be75e28d8ca43cbd",
      "fb57ce8321c9490285ab696646fa8baa",
      "c81189d1d1e2424fbb072b21e1ea225a",
      "e256fb7a24ed4214b4b9c3bf22370c75",
      "5b66ab13d857488bb80c43b0a66d9ad0",
      "e8dd932c45bb4265ab9c3f08e5a7acc7",
      "93c6b203a8b7450ea6a5cba176c92516",
      "28813465ab3c4e40adfeca7d5bc8fba5",
      "229e056620214caa9ca909d3838c2593",
      "26cb711bd9c24cb48d7563a96eda2153",
      "f09979a5e5f44f5db3f7f07e48b51248"
     ]
    },
    "id": "cgIl-M4TxtFa",
    "outputId": "954395d5-04d2-4e63-d0f2-2f652f1201bb"
   },
   "outputs": [],
   "source": [
    "# apply stemming to all texts\n",
    "for i in tqdm_notebook(range(len(texts))):           # tqdm_notebook creates the process bar below :)\n",
    "    text_stemmed = list(map(stemmer.stem, texts[i])) # apply stemming to each word in a text\n",
    "    texts[i] = ' '.join(text_stemmed)                # unite all stemmed words into a new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjzMbCCDxtFb",
    "outputId": "9b57f201-2a4e-47f4-8425-a41ec13bc1a8"
   },
   "outputs": [],
   "source": [
    "# example\n",
    "i = 1\n",
    "print(\"Label: \",   y[i])\n",
    "print(\"Text: \\n\",  texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sroCYURxtFb"
   },
   "source": [
    "## Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdf9R-3ixtFc"
   },
   "outputs": [],
   "source": [
    "#train test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_y, test_y = train_test_split(texts, y, test_size=0.33, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CavXrTKextFc"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPcVeQXhxtFd"
   },
   "source": [
    "TF-IDF measures importance of word in a corpus of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dpn33ACxtFe"
   },
   "source": [
    "<center><img src=\"https://github.com/shestakoff/hse_se_ml/blob/master/2020/s08-nlp/img/tfidf.jpg?raw=1\" width=\"800\"></center>\n",
    "Image from: http://filotechnologia.blogspot.com/2014/01/a-simple-java-class-for-tfidf-scoring.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NP6IYSXxtFf"
   },
   "outputs": [],
   "source": [
    "#calc tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fyc6RNTAxtFh",
    "outputId": "efab37fe-5423-4aa4-c33b-7ac171b85d07"
   },
   "outputs": [],
   "source": [
    "# Fit TF-IDF on train texts\n",
    "vectorizer = TfidfVectorizer(max_features = 25) # select the top 25 words\n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "# The top 25 words\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7i3buOOxtFi"
   },
   "outputs": [],
   "source": [
    "# Apply TF-IDF to train and test texts\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X  = vectorizer.fit_transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctCeTerfxtFj",
    "outputId": "8333e0c5-1667-45c5-fd03-e2426c281d96"
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "train_X.todense()[:2] # show the first 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98Cft0tuxtFk",
    "outputId": "c4a4f330-d0d3-451d-9d72-c75b08be8f71"
   },
   "outputs": [],
   "source": [
    "# word - column in X accordance\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blDiFZ14xtFl"
   },
   "source": [
    "## Fit a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "aOTOfLQrxtFm",
    "outputId": "d0df5b7a-2580-4d75-b80d-ecb7f7fd23c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJSHeayOxtFn"
   },
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YKw089DxtFo",
    "outputId": "000f34a8-5719-4103-a9c9-b98893a23e9b"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(test_X)\n",
    "proba  = model.predict_proba(test_X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print(\"ACCURACY = {}\".format(accuracy_score(test_y, predict)))\n",
    "print(\"ROC-AUC =  {}\".format(roc_auc_score(test_y, proba[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ARzPIfrxtFp"
   },
   "source": [
    "**Results:** 25 words are too small to estimate news sentiment properly. We need more words. But how will we deal with high dimensionalities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McJNWB4hxtFp"
   },
   "source": [
    "# Latent Semantic Analysis (LSA)\n",
    "\n",
    "LSA is just similar to PCA. It reduces dimension of the input matrix X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAOB53oIxtFp"
   },
   "source": [
    "<center><img src=\"https://github.com/shestakoff/hse_se_ml/blob/master/2020/s08-nlp/img/lsa.jpg?raw=1\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hae2t5agxtFp"
   },
   "source": [
    "Let's take more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "t2-1nb4qxtFq",
    "outputId": "a25a8e4a-e817-4cdb-a20b-17ef71d3e5d3"
   },
   "outputs": [],
   "source": [
    "# Fit TF-IDF on train texts\n",
    "vectorizer = TfidfVectorizer(max_features = 40000)\n",
    "vectorizer.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L52EkSffxtFq"
   },
   "outputs": [],
   "source": [
    "# Apply TF-IDF to train and test texts\n",
    "train_X = vectorizer.transform(train_texts)\n",
    "test_X  = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vw8I1NosxtFr",
    "outputId": "4cebeba0-3db0-4db7-a805-9113cdd2529b"
   },
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03pjeaGdxtFr"
   },
   "source": [
    "Now we have 40000 words. But it is too large for a classification model. Let's use LSA to reduce dimension. In sklearn LSA is TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "2KfsQyTWxtFs",
    "outputId": "6a84fe70-78c3-4bad-9065-acc0ec286a96"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# fit SVD decomposition\n",
    "svd = TruncatedSVD(n_components = 1000)\n",
    "svd.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AocSG1ckxtFs"
   },
   "outputs": [],
   "source": [
    "# apply SVD to train and test samples\n",
    "train_svd_X = svd.transform(train_X)\n",
    "test_svd_X  = svd.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YByWDNI1xtFs",
    "outputId": "ece47414-7759-4477-9977-92b05850d4e7"
   },
   "outputs": [],
   "source": [
    "train_svd_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-4gHm6NxtFt"
   },
   "source": [
    "## Fit a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "qJAU2cSzxtFt",
    "outputId": "34cfac41-0e75-49fe-80a3-3fd4274c5f01"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(train_svd_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0HnBamIxtFt"
   },
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ka-R2itfxtFu",
    "outputId": "31bfa5de-9799-4689-c57f-dfcc0e1962a0"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(test_svd_X)\n",
    "proba   = model.predict_proba(test_svd_X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print(\"ACCURACY = {}\".format(accuracy_score(test_y, predict)))\n",
    "print(\"ROC-AUC =  {}\".format(roc_auc_score(test_y, proba[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VuIPv4rxtFu"
   },
   "source": [
    "# Kaggle competition\n",
    "\n",
    "https://www.kaggle.com/c/explicit-content-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3tEnw58xtFv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyoadfe",
   "language": "python",
   "name": "pyoadfe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "229e056620214caa9ca909d3838c2593": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26cb711bd9c24cb48d7563a96eda2153": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28813465ab3c4e40adfeca7d5bc8fba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b66ab13d857488bb80c43b0a66d9ad0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c08bdd1764241f5be75e28d8ca43cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb57ce8321c9490285ab696646fa8baa",
       "IPY_MODEL_c81189d1d1e2424fbb072b21e1ea225a",
       "IPY_MODEL_e256fb7a24ed4214b4b9c3bf22370c75"
      ],
      "layout": "IPY_MODEL_5b66ab13d857488bb80c43b0a66d9ad0"
     }
    },
    "93c6b203a8b7450ea6a5cba176c92516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c81189d1d1e2424fbb072b21e1ea225a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28813465ab3c4e40adfeca7d5bc8fba5",
      "max": 8263,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_229e056620214caa9ca909d3838c2593",
      "value": 8263
     }
    },
    "e256fb7a24ed4214b4b9c3bf22370c75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26cb711bd9c24cb48d7563a96eda2153",
      "placeholder": "​",
      "style": "IPY_MODEL_f09979a5e5f44f5db3f7f07e48b51248",
      "value": " 8263/8263 [03:28&lt;00:00, 55.81it/s]"
     }
    },
    "e8dd932c45bb4265ab9c3f08e5a7acc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f09979a5e5f44f5db3f7f07e48b51248": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb57ce8321c9490285ab696646fa8baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8dd932c45bb4265ab9c3f08e5a7acc7",
      "placeholder": "​",
      "style": "IPY_MODEL_93c6b203a8b7450ea6a5cba176c92516",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
