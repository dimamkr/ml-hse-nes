{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ksn9azeZa-Zr",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702453591048,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "Ksn9azeZa-Zr"
   },
   "outputs": [],
   "source": [
    "#pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VE4Pgxpla-Zv",
   "metadata": {
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1702453598781,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "VE4Pgxpla-Zv"
   },
   "outputs": [],
   "source": [
    "#pip install transliterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nbo6LXl-a-Zw",
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1702453601278,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "Nbo6LXl-a-Zw"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import typing as tp\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset as LFMDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from transliterate import translit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vmP5KJ8na-Zx",
   "metadata": {
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1702453603128,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "vmP5KJ8na-Zx"
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"data_kion.zip\"\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ZIrHiPXE2Dv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9284,
     "status": "ok",
     "timestamp": 1702453507545,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "1ZIrHiPXE2Dv",
    "outputId": "ea81e721-b3a8-4aee-c59f-d3dd4d6ae304"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07db2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hse-ds/ml-hse-nes/blob/main/2022/seminars/seminar10_recsys/data_kion.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O-H992C8a-Zx",
   "metadata": {
    "id": "O-H992C8a-Zx"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOJ65av2a-Zz",
   "metadata": {
    "id": "vOJ65av2a-Zz"
   },
   "source": [
    "Для целей семинара используем анонимизированные данные по просмотрам в онлайн-кинотеатре Кион. Мы имеем данные по действиям примерно за полгода, а также признаки пользователей и контента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0qSVo0cja-Z0",
   "metadata": {
    "executionInfo": {
     "elapsed": 9823,
     "status": "ok",
     "timestamp": 1702453614183,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "0qSVo0cja-Z0"
   },
   "outputs": [],
   "source": [
    "with ZipFile(PATH_TO_DATA) as zf:\n",
    "\n",
    "    with zf.open(\"interactions.csv\") as f:\n",
    "        interactions = pd.read_csv(f)\n",
    "\n",
    "    with zf.open(\"items.csv\") as f:\n",
    "        items = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alg_A3J3a-Z0",
   "metadata": {
    "id": "alg_A3J3a-Z0"
   },
   "source": [
    "Определим последний доступный день в выборке как тестовый, а 3 месяца до него - обучающей выборкой.\n",
    "\n",
    "Для простоты:\n",
    "- удачным взаимодействием будем считать просмотр любой длительности и при обучении будем использовать только эту информацию, игнорируя данные о признаках пользователей и контента\n",
    "- не будем обрабатывать \"холодных\" пользователей, просто удалим их из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2Ovzaaoa-Z1",
   "metadata": {
    "id": "z2Ovzaaoa-Z1"
   },
   "outputs": [],
   "source": [
    "train = interactions.loc[\n",
    "    (interactions[\"last_watch_dt\"] >= \"2021-05-21\")\n",
    "    & (interactions[\"last_watch_dt\"] <= \"2021-08-21\"),\n",
    "    [\"user_id\", \"item_id\"]\n",
    "]\n",
    "\n",
    "test = interactions.loc[interactions[\"last_watch_dt\"] == \"2021-08-22\", [\"user_id\", \"item_id\"]]\n",
    "test = test.loc[test[\"user_id\"].isin(train[\"user_id\"]) & test[\"item_id\"].isin(train[\"item_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZZYfuRJaa-Z1",
   "metadata": {
    "id": "ZZYfuRJaa-Z1"
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, items[[\"item_id\", \"title\", \"genres\"]], on=\"item_id\")\n",
    "test = pd.merge(test, items[[\"item_id\", \"title\", \"genres\"]], on=\"item_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8xYRp760a-Z2",
   "metadata": {
    "id": "8xYRp760a-Z2"
   },
   "source": [
    "## Добавление аватаров в обучающую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Elr1Uwgda-Z2",
   "metadata": {
    "id": "Elr1Uwgda-Z2"
   },
   "source": [
    "Далее для построения рекомендаций будем использовать алгоритм матричного разложения из библиотеки LightFM. Для формирования рекомендаций для аватаров необходимо, чтобы действия аватаров были в обучающей выборке.\n",
    "\n",
    "Отметим, что добавляя действия аватаров в обучающую выборку, мы несколько изменяем ее распределение. Обычно этим можно пренебречь, т.к. объем обучающей выборки (в нашем случае 5 млн наблюдений) значительно больше объема действий аватаров (10 наблюдений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nez4Y-W7a-Z3",
   "metadata": {
    "id": "Nez4Y-W7a-Z3"
   },
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Джон Уик\",\n",
    "    \"Заложница\",\n",
    "    \"Перевозчик\",\n",
    "    \"Форсаж: Хоббс и Шоу\",\n",
    "    \"Терминатор 3: Восстание машин\"\n",
    "]\n",
    "avatar_interactions_action = pd.DataFrame({\"user_id\": \"avatar_action\", \"title\": titles})\n",
    "avatar_interactions_action = avatar_interactions_action.merge(items[[\"item_id\", \"title\", \"genres\"]], on=\"title\")\n",
    "avatar_interactions_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Y8JrVZ3a-Z4",
   "metadata": {
    "id": "2Y8JrVZ3a-Z4"
   },
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Тупой и еще тупее 2\",\n",
    "    \"Типа крутые легавые\",\n",
    "    \"Голый пистолет\",\n",
    "    \"Убойные каникулы\",\n",
    "    \"Карты, деньги, два ствола\"\n",
    "]\n",
    "avatar_interactions_comedy = pd.DataFrame({\"user_id\": \"avatar_comedy\", \"title\": titles})\n",
    "avatar_interactions_comedy = avatar_interactions_comedy.merge(items[[\"item_id\", \"title\", \"genres\"]], on=\"title\")\n",
    "avatar_interactions_comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bmiyJXKqa-Z4",
   "metadata": {
    "id": "bmiyJXKqa-Z4"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, avatar_interactions_action, avatar_interactions_comedy], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pCEcc92Ha-Z5",
   "metadata": {
    "id": "pCEcc92Ha-Z5"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PxmB7sxla-Z5",
   "metadata": {
    "id": "PxmB7sxla-Z5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lfm_dataset = LFMDataset()\n",
    "lfm_dataset.fit(\n",
    "    users=train[\"user_id\"].values,\n",
    "    items=train[\"item_id\"].values,\n",
    ")\n",
    "\n",
    "train_matrix, _ = lfm_dataset.build_interactions(zip(*train[[\"user_id\", \"item_id\"]].values.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z5MK3FVoa-Z6",
   "metadata": {
    "id": "z5MK3FVoa-Z6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lfm_model = LightFM(\n",
    "    learning_rate=0.01,\n",
    "    loss='warp',\n",
    "    no_components=64,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "lfm_model.fit(\n",
    "    interactions=train_matrix,\n",
    "    epochs=20,\n",
    "    num_threads=20,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G746N_jza-Z6",
   "metadata": {
    "id": "G746N_jza-Z6"
   },
   "source": [
    "## Рекомендации для аватаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zM6TCh8La-Z7",
   "metadata": {
    "id": "zM6TCh8La-Z7"
   },
   "outputs": [],
   "source": [
    "n_recommendations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4_WgPNZTa-Z7",
   "metadata": {
    "id": "4_WgPNZTa-Z7"
   },
   "outputs": [],
   "source": [
    "id_item_mapping = {v: k for k, v in lfm_dataset._item_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0gCQJWkPa-Z7",
   "metadata": {
    "id": "0gCQJWkPa-Z7"
   },
   "outputs": [],
   "source": [
    "def get_n_recommendations_for_user(\n",
    "    user_id: str,\n",
    "    model: LightFM,\n",
    "    train_matrix: coo_matrix,\n",
    "    user_to_id: tp.Dict[str, int],\n",
    "    id_to_item: tp.Dict[int, str],\n",
    "    n_recommendations: int\n",
    ") -> pd.DataFrame:\n",
    "    user_inner_id = user_to_id[user_id]\n",
    "    scores = model.predict(\n",
    "        user_ids=user_inner_id,\n",
    "        item_ids=np.arange(train_matrix.shape[1]),\n",
    "        num_threads=20\n",
    "    )\n",
    "    user_watched_items = train_matrix.col[train_matrix.row == user_inner_id]\n",
    "    scores[user_watched_items] = -np.inf\n",
    "\n",
    "    recommended_item_inner_ids = np.argpartition(scores, -np.arange(n_recommendations))[\n",
    "        -n_recommendations:\n",
    "    ][::-1]\n",
    "    recommended_item_ids = [id_to_item[x] for x in recommended_item_inner_ids]\n",
    "    return recommended_item_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wNzyUBoDa-Z8",
   "metadata": {
    "id": "wNzyUBoDa-Z8"
   },
   "outputs": [],
   "source": [
    "user_id = \"avatar_action\"\n",
    "\n",
    "recommended_items = get_n_recommendations_for_user(\n",
    "    user_id=user_id,\n",
    "    model=lfm_model,\n",
    "    train_matrix=train_matrix,\n",
    "    user_to_id=lfm_dataset._user_id_mapping,\n",
    "    id_to_item=id_item_mapping,\n",
    "    n_recommendations=n_recommendations\n",
    ")\n",
    "pd.DataFrame({\"user_id\": user_id, \"item_id\": recommended_items}).merge(items[[\"item_id\", \"title\", \"genres\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ag45GJCga-Z8",
   "metadata": {
    "id": "Ag45GJCga-Z8"
   },
   "outputs": [],
   "source": [
    "user_id = \"avatar_comedy\"\n",
    "\n",
    "recommended_items = get_n_recommendations_for_user(\n",
    "    user_id=user_id,\n",
    "    model=lfm_model,\n",
    "    train_matrix=train_matrix,\n",
    "    user_to_id=lfm_dataset._user_id_mapping,\n",
    "    id_to_item=id_item_mapping,\n",
    "    n_recommendations=n_recommendations\n",
    ")\n",
    "pd.DataFrame({\"user_id\": user_id, \"item_id\": recommended_items}).merge(items[[\"item_id\", \"title\", \"genres\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85Fn8Ra1a-Z9",
   "metadata": {
    "id": "85Fn8Ra1a-Z9"
   },
   "outputs": [],
   "source": [
    "# самые просматриваемые в обучающей выборке\n",
    "train[\"title\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0Bp43NvBa-Z-",
   "metadata": {
    "id": "0Bp43NvBa-Z-"
   },
   "source": [
    "Мы получили, что рекомендации для аватаров имеют сильное пересечение, обусловленное перекосом к рекомендациям популярного контента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kaweIVSBa-Z-",
   "metadata": {
    "id": "kaweIVSBa-Z-"
   },
   "source": [
    "##  Попробуем побороться с перекосом к популярным"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q2vekHzfa-Z-",
   "metadata": {
    "id": "Q2vekHzfa-Z-"
   },
   "source": [
    "Алгоритм обучает для каждого пользователя $u$ и товара $i$ соответственно смещения $b_u$, $b_i$ и эмбеддинги $p_u$, $q_i$. Для формирования рекомендаций для пользователя выбираются товары, имеющие наибольшие значения скоров, определяющихся по формуле:\n",
    "\n",
    "$$score_{ui} = b_u + b_i + p_u \\cdot q_i = b_u + b_i + \\cos ( p_u, q_i ) \\cdot || p_u || \\cdot || q_i || .$$\n",
    "\n",
    "Часто перекос к популярным выражается в больших значениях смещений или норм эмбеддингов у популярных товаров. В таких случаях может помочь переход от ранжирования по значениям скалярных произведений к ранжированию по косинусам угла между эмбеддингами пользователей и товаров.\n",
    "\n",
    "Для перехода к косинусам согласно формуле выше достаточно заменить $b_u$ и $b_i$ нулями и привести нормы $p_u$ и $q_i$ к единицам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N1_Dw85Va-Z_",
   "metadata": {
    "id": "N1_Dw85Va-Z_"
   },
   "outputs": [],
   "source": [
    "lfm_model_cos = deepcopy(lfm_model)\n",
    "\n",
    "lfm_model_cos.item_biases = np.zeros_like(lfm_model_cos.item_biases)\n",
    "lfm_model_cos.user_biases = np.zeros_like(lfm_model_cos.user_biases)\n",
    "\n",
    "lfm_model_cos.item_embeddings = normalize(lfm_model_cos.item_embeddings)\n",
    "lfm_model_cos.user_embeddings = normalize(lfm_model_cos.user_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79SFrS9Wa-Z_",
   "metadata": {
    "id": "79SFrS9Wa-Z_"
   },
   "outputs": [],
   "source": [
    "user_id = \"avatar_action\"\n",
    "\n",
    "recommended_items = get_n_recommendations_for_user(\n",
    "    user_id=user_id,\n",
    "    model=lfm_model_cos,\n",
    "    train_matrix=train_matrix,\n",
    "    user_to_id=lfm_dataset._user_id_mapping,\n",
    "    id_to_item=id_item_mapping,\n",
    "    n_recommendations=n_recommendations\n",
    ")\n",
    "pd.DataFrame({\"user_id\": user_id, \"item_id\": recommended_items}).merge(items[[\"item_id\", \"title\", \"genres\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k9Rh4jBna-Z_",
   "metadata": {
    "id": "k9Rh4jBna-Z_"
   },
   "outputs": [],
   "source": [
    "user_id = \"avatar_comedy\"\n",
    "\n",
    "recommended_items = get_n_recommendations_for_user(\n",
    "    user_id=user_id,\n",
    "    model=lfm_model_cos,\n",
    "    train_matrix=train_matrix,\n",
    "    user_to_id=lfm_dataset._user_id_mapping,\n",
    "    id_to_item=id_item_mapping,\n",
    "    n_recommendations=n_recommendations\n",
    ")\n",
    "pd.DataFrame({\"user_id\": user_id, \"item_id\": recommended_items}).merge(items[[\"item_id\", \"title\", \"genres\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u_xZo_Noa-aA",
   "metadata": {
    "id": "u_xZo_Noa-aA"
   },
   "source": [
    "Видно, что рекомендации стали более персонализированными для аватаров и исчезло преобладание популярного контента. Однако говорить о том, что новая версия модели лучше рано. Выводы стоит делать после того, как будут в том числе проведены количественные оценки качества (оффлайн и онлайн метрики)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kc5-vCkWa-aB",
   "metadata": {
    "id": "kc5-vCkWa-aB"
   },
   "source": [
    "## Похожие фильмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BczJwdXBa-aC",
   "metadata": {
    "id": "BczJwdXBa-aC"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def get_n_similar_movies(\n",
    "    item_id: str,\n",
    "    model: LightFM,\n",
    "    item_to_id: tp.Dict[str, int],\n",
    "    id_to_item: tp.Dict[int, str],\n",
    "    n_recommendations: int\n",
    ") -> pd.DataFrame:\n",
    "    item_inner_id = item_to_id[item_id]\n",
    "    _, embeddings = model.get_item_representations()\n",
    "\n",
    "    similarities = 1 - cdist(embeddings[item_inner_id].reshape(1, -1), embeddings, metric=\"cosine\")\n",
    "    similarities = similarities[0]\n",
    "    similarities[item_inner_id] = -np.inf\n",
    "\n",
    "    similar_movie_inner_ids = np.argsort(-similarities)[:10]\n",
    "    similar_movie_ids = [id_to_item[x] for x in similar_movie_inner_ids]\n",
    "    return similar_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4Ce2MRHa-aD",
   "metadata": {
    "id": "c4Ce2MRHa-aD"
   },
   "outputs": [],
   "source": [
    "item_id = 7671  # Джон Уик\n",
    "\n",
    "similar_movies = get_n_similar_movies(\n",
    "    item_id=item_id,\n",
    "    model=lfm_model_cos,\n",
    "    item_to_id=lfm_dataset._item_id_mapping,\n",
    "    id_to_item=id_item_mapping,\n",
    "    n_recommendations=n_recommendations\n",
    ")\n",
    "pd.DataFrame({\"item_id\": similar_movies}).merge(items[[\"item_id\", \"title\", \"genres\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JAOC6TCYa-aE",
   "metadata": {
    "id": "JAOC6TCYa-aE"
   },
   "outputs": [],
   "source": [
    "item_id = 2323  # Форсаж: Хоббс и Шоу\n",
    "\n",
    "similar_movies = get_n_similar_movies(\n",
    "    item_id=item_id,\n",
    "    model=lfm_model,\n",
    "    item_to_id=lfm_dataset._item_id_mapping,\n",
    "    id_to_item=id_item_mapping,\n",
    "    n_recommendations=n_recommendations\n",
    ")\n",
    "pd.DataFrame({\"item_id\": similar_movies}).merge(items[[\"item_id\", \"title\", \"genres\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1lNLDS5ea-aE",
   "metadata": {
    "id": "1lNLDS5ea-aE"
   },
   "source": [
    "## Расчет рекомендаций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "--N4tVfna-aE",
   "metadata": {
    "id": "--N4tVfna-aE"
   },
   "source": [
    "Сформируем таблицы рекомендаций для пользователей из тестовой выборки.\n",
    "\n",
    "Далее с помощью этих таблиц будут оценены метрики beyond accuracy. Методологически вернее оценивать данные метрики на всей пользовательской базе, а не только для пользователей, имеющих действия в тестовой выборке. Здесь мы этим пренебрежем для экономии вычислительных ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9gstu3-aa-aF",
   "metadata": {
    "id": "9gstu3-aa-aF"
   },
   "outputs": [],
   "source": [
    "models_dict = {\"lfm\": lfm_model, \"lfm_cos\": lfm_model_cos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FRKZzSnza-aF",
   "metadata": {
    "id": "FRKZzSnza-aF"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "recommendations_dict = {}\n",
    "for model_name, model in models_dict.items():\n",
    "    recommendations = pd.DataFrame({\"user_id\": test[\"user_id\"].unique()})\n",
    "    recommendations[\"item_id\"] = recommendations[\"user_id\"].apply(\n",
    "        get_n_recommendations_for_user,\n",
    "        args=(\n",
    "            model,\n",
    "            train_matrix,\n",
    "            lfm_dataset._user_id_mapping,\n",
    "            id_item_mapping,\n",
    "            n_recommendations\n",
    "        ),\n",
    "    )\n",
    "    recommendations = recommendations.explode(\"item_id\")\n",
    "    recommendations[\"rank\"] = recommendations.groupby([\"user_id\"]).cumcount() + 1\n",
    "    recommendations_dict[model_name] = recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SB__vCpya-aG",
   "metadata": {
    "id": "SB__vCpya-aG"
   },
   "source": [
    "# Оценка метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pX-g8buKa-aG",
   "metadata": {
    "id": "pX-g8buKa-aG"
   },
   "source": [
    "Эти метрики оценивают качество топ-N рекомендаций. В рекомендательные системы напрямую перекочевали из методов оценки качества бинарной классификации.\n",
    "Все считается на основе 4 базовых случаев:\n",
    "* True positive  (TP) - модель рекомендовала объект, с которым пользователь провзаимодействовал\n",
    "* False positive (FP) - модель рекомендовала объект, с которым пользователь не провзаимодействовал\n",
    "* True negative  (TN) - модель не рекомендовала объект, с которым пользователь не провзаимодействовал\n",
    "* False negative (FN) - модель не рекомендовала объект, с которым пользователь провзаимодействовал\n",
    "\n",
    "Что из этого всего важней? В первую очередь это True positive. Мы хотим строить наиболее релевантные рекомендации для пользователя.\n",
    "Во вторую очередь это False negative, опять же потому, что мы не хотим, чтобы модель \"теряла\" релевантные рекомендации.\n",
    "\n",
    "А что с FP и TN? На самом деле, эти величины не показательны. Они обычно очень больше, так как пользователи взаимодействуют с очень малым количество объектов относительно общего числа объектов.\n",
    "И практика показывает, что этими значениями можно пренебречь.\n",
    "\n",
    "Для измерения доли TP и FN применяются следующие метрики:\n",
    "* **Precision@K** - доля релевантных рекомендаций среди всех рекомендаций\n",
    "    * Формула - `TP / (TP + FP)`\n",
    "    * Можно заметить, что под positives мы понимаем рекомендованные объекты, то есть наш топ-К, значит `TP + FP = K`\n",
    "    * Итоговая формула - `TP / K`\n",
    "    * Считаем по каждому пользователю и для некторых К\n",
    "    * Усредняем по всем пользователя\n",
    "* **Recall@K** - доля релевантных рекомендаций среди всех релевантных объектов\n",
    "    * Формула - `TP / (TP + FN)`\n",
    "    * `TP + FN` это количество известных релевантых объектов для пользователя\n",
    "    * Считаем по каждому пользователю и для некторых К\n",
    "    * Усредняем по всем пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QnjaL2bXa-aH",
   "metadata": {
    "id": "QnjaL2bXa-aH"
   },
   "outputs": [],
   "source": [
    "df_true = pd.DataFrame({\n",
    "    'user_id': ['Аня',                'Боря',               'Вася',         'Вася'],\n",
    "    'item_id': ['Джентельмены удачи', '451° по Фаренгейту', 'Зеленая миля', 'Побег из Шоушенка'],\n",
    "})\n",
    "df_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6jUJvvnCa-aI",
   "metadata": {
    "id": "6jUJvvnCa-aI"
   },
   "outputs": [],
   "source": [
    "df_recs = pd.DataFrame({\n",
    "    'user_id': [\n",
    "        'Аня', 'Аня', 'Аня',\n",
    "        'Боря', 'Боря', 'Боря',\n",
    "        'Вася', 'Вася', 'Вася',\n",
    "    ],\n",
    "    'item_id': [\n",
    "        'Служебный роман', 'Бриллиантовая рука', '12 стульев',\n",
    "        '451° по Фаренгейту', '1984', 'Бегущий по лезвию',\n",
    "        'Оно', 'Сияние', 'Зеленая миля',\n",
    "    ],\n",
    "    'rank': [\n",
    "        1, 2, 3,\n",
    "        1, 2, 3,\n",
    "        1, 2, 3,\n",
    "    ]\n",
    "})\n",
    "df_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iM1IkvUSa-aI",
   "metadata": {
    "id": "iM1IkvUSa-aI"
   },
   "outputs": [],
   "source": [
    "df_merged = df_true.set_index(['user_id', 'item_id']).join(df_recs.set_index(['user_id', 'item_id']), how='left')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IfykCx5Va-aJ",
   "metadata": {
    "id": "IfykCx5Va-aJ"
   },
   "source": [
    "Вначале посчитаем метрик для топ-2 (т.е. К = 2). Алгоритм следующий:\n",
    "* Релевантные объекты, которые не были рекомендованы игнорируем (NaN)\n",
    "* Определяем, какие релеватные рекомендации попали в топ-2 (hit)\n",
    "    * True positive для каждого пользователя\n",
    "* Делим TP на K  \n",
    "* Считаем Precision@K для каждого пользователя как сумму его TP/K\n",
    "* Все Precision@K усредняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6lcg7ykta-aJ",
   "metadata": {
    "id": "6lcg7ykta-aJ"
   },
   "outputs": [],
   "source": [
    "df_merged['hit@2'] = df_merged['rank'] <= 2\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dr56LXP5a-aJ",
   "metadata": {
    "id": "dr56LXP5a-aJ"
   },
   "outputs": [],
   "source": [
    "df_merged['hit@2/2'] = df_merged['hit@2'] / 2\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spAKsaita-aK",
   "metadata": {
    "id": "spAKsaita-aK"
   },
   "outputs": [],
   "source": [
    "df_prec2 = df_merged.groupby(level=0)['hit@2/2'].sum()\n",
    "df_prec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R8NdYVc8a-aK",
   "metadata": {
    "id": "R8NdYVc8a-aK"
   },
   "outputs": [],
   "source": [
    "print(f'Precision@2 - {df_prec2.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7CMWMdNBa-aL",
   "metadata": {
    "id": "7CMWMdNBa-aL"
   },
   "outputs": [],
   "source": [
    "users_count = df_merged.index.get_level_values('user_id').nunique()\n",
    "for k in [1, 2, 3]:\n",
    "    hit_k = f'hit@{k}'\n",
    "    df_merged[hit_k] = df_merged['rank'] <= k\n",
    "    print(f'Precision@{k} = {(df_merged[hit_k] / k).sum() / users_count:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CII1drs-a-aL",
   "metadata": {
    "id": "CII1drs-a-aL"
   },
   "source": [
    "C Recall@K похожая история, нам также нужно получить hit@K, но делить уже будем на количество релевантных объектов у пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iPQM-Igha-aM",
   "metadata": {
    "id": "iPQM-Igha-aM"
   },
   "outputs": [],
   "source": [
    "df_merged['users_item_count'] = df_merged.groupby(level='user_id')['rank'].transform(np.size)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crPyNGa4a-aM",
   "metadata": {
    "id": "crPyNGa4a-aM"
   },
   "outputs": [],
   "source": [
    "for k in [1, 2, 3]:\n",
    "    hit_k = f'hit@{k}'\n",
    "    # Уже посчитано\n",
    "    # df_merged[hit_k] = df_merged['rank'] <= k\n",
    "    print(f\"Recall@{k} = {(df_merged[hit_k] / df_merged['users_item_count']).sum() / users_count:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VNGFfqC8a-aM",
   "metadata": {
    "id": "VNGFfqC8a-aM"
   },
   "source": [
    "Precision@K и Recall@K неплохие метрики, чтобы оценить качество рекомендаций, но они учитывают только \"попадания\" (hits, true positives).\n",
    "Но на самом деле нам важно насколько высоко по позициям находятся эти самые попадания.\n",
    "\n",
    "Простой пример, пусть две модели рекомендаций для одного пользователя получили такие hit@4 на тесте:\n",
    "* model1 - 1, 0, 0, 1\n",
    "* model2 - 1, 0, 1, 0\n",
    "\n",
    "Precision@4 для них будет одинаковый - 0.5, хотя model2 немного лучше, так как 2-ое попадание находится выше, чем у model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MM49FHxwa-aN",
   "metadata": {
    "id": "MM49FHxwa-aN"
   },
   "source": [
    "# Оценка метрик ранжирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LkOK039ya-aN",
   "metadata": {
    "id": "LkOK039ya-aN"
   },
   "source": [
    "Эти метрики оценивают качество топ-N рекомендаций c учетом рангов/позиций. Основная идея - оценить \"попадания\" с весом, зависящим от позиции (обычно это обратная пропорциальная зависимость, то есть чем больше позиция, тем меньше вес).\n",
    "Основные метрики следующие:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OAYKEIxDa-aN",
   "metadata": {
    "id": "OAYKEIxDa-aN"
   },
   "source": [
    "**Mean Reciprocal Rank**\n",
    "\n",
    "$$ MRR = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{1}{rank_i}, $$\n",
    "\n",
    "где $N$ - количество пользователей, а $rank_i$ - позиция первой релевантной рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y0IANyVqa-aN",
   "metadata": {
    "id": "Y0IANyVqa-aN"
   },
   "source": [
    "**Mean Average Precision**\n",
    "\n",
    "$$ MAP@k = \\frac{1}{N} \\sum_{i=1}^{N} AP@k(user_i) $$\n",
    "\n",
    "$$ AP@k = \\frac{1}{c_{user}} \\sum_{i=1}^{k} Precision@i * rel_i $$\n",
    "\n",
    "То есть MAP - это усреднение AveragePrecision по всем пользователям.\n",
    "А AveragePrecision в свою очередь, это средний Precision@K по релевантным объектам одного пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HAVy7LU4a-aN",
   "metadata": {
    "id": "HAVy7LU4a-aN"
   },
   "outputs": [],
   "source": [
    "df_merged = df_true.set_index(['user_id', 'item_id']).join(df_recs.set_index(['user_id', 'item_id']), how='left')\n",
    "df_merged = df_merged.sort_values(by=['user_id', 'rank'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N7X9l9PXa-aO",
   "metadata": {
    "id": "N7X9l9PXa-aO"
   },
   "outputs": [],
   "source": [
    "df_merged['reciprocal_rank'] = 1 / df_merged['rank']\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J6AQDi-5a-aO",
   "metadata": {
    "id": "J6AQDi-5a-aO"
   },
   "outputs": [],
   "source": [
    "mrr = df_merged.groupby(level='user_id')['reciprocal_rank'].max()\n",
    "mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Za178KY_a-aO",
   "metadata": {
    "id": "Za178KY_a-aO"
   },
   "outputs": [],
   "source": [
    "print(f\"MRR = {mrr.fillna(0).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FWJszrD4a-aP",
   "metadata": {
    "id": "FWJszrD4a-aP"
   },
   "outputs": [],
   "source": [
    "df_merged['cumulative_rank'] = df_merged.groupby(level='user_id').cumcount() + 1\n",
    "df_merged['cumulative_rank'] = df_merged['cumulative_rank'] / df_merged['rank']\n",
    "df_merged['users_item_count'] = df_merged.groupby(level='user_id')['rank'].transform(np.size)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8iUFkqixa-aP",
   "metadata": {
    "id": "8iUFkqixa-aP"
   },
   "outputs": [],
   "source": [
    "users_count = df_merged.index.get_level_values('user_id').nunique()\n",
    "map3 = (df_merged[\"cumulative_rank\"] / df_merged[\"users_item_count\"]).sum() / users_count\n",
    "print(f\"MAP@3 = {map3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zWWrlzg3a-aP",
   "metadata": {
    "id": "zWWrlzg3a-aP"
   },
   "source": [
    "## Оценка метрик на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aB8sAElza-aP",
   "metadata": {
    "id": "aB8sAElza-aP"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(df_true, df_pred, top_N):\n",
    "    result = {}\n",
    "    test_recs = df_true.set_index(['user_id', 'item_id']).join(df_pred.set_index(['user_id', 'item_id']))\n",
    "    test_recs = test_recs.sort_values(by=['user_id', 'rank'])\n",
    "\n",
    "    test_recs['users_item_count'] = test_recs.groupby(level='user_id')['rank'].transform(np.size)\n",
    "    test_recs['reciprocal_rank'] = (1 / test_recs['rank']).fillna(0)\n",
    "    test_recs['cumulative_rank'] = test_recs.groupby(level='user_id').cumcount() + 1\n",
    "    test_recs['cumulative_rank'] = test_recs['cumulative_rank'] / test_recs['rank']\n",
    "\n",
    "    users_count = test_recs.index.get_level_values('user_id').nunique()\n",
    "    for k in range(1, top_N + 1):\n",
    "        hit_k = f'hit@{k}'\n",
    "        test_recs[hit_k] = test_recs['rank'] <= k\n",
    "        result[f'Precision@{k}'] = (test_recs[hit_k] / k).sum() / users_count\n",
    "        result[f'Recall@{k}'] = (test_recs[hit_k] / test_recs['users_item_count']).sum() / users_count\n",
    "\n",
    "    result[f'MAP@{top_N}'] = (test_recs[\"cumulative_rank\"] / test_recs[\"users_item_count\"]).sum() / users_count\n",
    "    result[f'MRR'] = test_recs.groupby(level='user_id')['reciprocal_rank'].max().mean()\n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kcqBwe_0a-aQ",
   "metadata": {
    "id": "kcqBwe_0a-aQ"
   },
   "outputs": [],
   "source": [
    "compute_metrics(test, recommendations_dict[\"lfm\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qxqR5Qtqa-aQ",
   "metadata": {
    "id": "qxqR5Qtqa-aQ"
   },
   "outputs": [],
   "source": [
    "compute_metrics(test, recommendations_dict[\"lfm_cos\"], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_Z-qrMXla-aQ",
   "metadata": {
    "id": "_Z-qrMXla-aQ"
   },
   "source": [
    "Из значений метрик видно, что модель со скосом к популярному имеет бОльшие значения метрик, это логично, тк популярные фильмы, просматриваемые пользователями в обучающем периоде, обычно популярны и в течение тестового периода. Здесь стоит отметить, что в тч из-за этого наблюдения выбор модели для раскатки на реальных пользователях, основанный на значениях оффлайн метрик, в рекомендациях обычно не оправдан. Например, в описанном случае совсем необязательно пользователям больше понравятся рекомендации популярного контента относительно более персонализированного. Честным способом сравнения моделей рекомендаций является проведение АБ-теста, в рамках которого для разных алгоритмов будут сравниваться бизнес-метрики (в случае онлайн-кинотеатра это могут быть метрики метрики среднего времени просмотра контента за тестовый период, среднее количество просмотренных тайтлов и тд)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-KPkVLCia-aR",
   "metadata": {
    "id": "-KPkVLCia-aR"
   },
   "source": [
    "# Оценка beyond accuracy метрик\n",
    "## Intra-List Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ElfAGcMYa-aR",
   "metadata": {
    "id": "ElfAGcMYa-aR"
   },
   "source": [
    "Оценим для обеих моделей среднее разнообразие контента в полках с помощью метрики $ILD$:\n",
    "\n",
    "$$ ILD = \\frac{1}{|R| ( |R| - 1 )} \\sum_{i \\in R} \\sum_{j \\in R} d(i, j) . $$\n",
    "\n",
    "В качестве расстояния $d(i, j)$ используем [расстояние Хэмминга](https://neerc.ifmo.ru/wiki/index.php?title=Расстояние_Хэмминга) между one-hot векторами жанров. Пример расчета:\n",
    "\n",
    "##### <center>d(10<font color='blue'>1</font>1<font color='blue'>1</font>01, 10<font color='red'>0</font>1<font color='red'>0</font>01) = 2.</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GYH5PDx7a-aR",
   "metadata": {
    "id": "GYH5PDx7a-aR"
   },
   "source": [
    "Для оценки расстояния Хэмминга между фильмами вытянем список жанров в one-hot векторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i_GKS99Pa-aR",
   "metadata": {
    "id": "i_GKS99Pa-aR"
   },
   "outputs": [],
   "source": [
    "items[[\"item_id\", \"genres\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z1Za-5fOa-aS",
   "metadata": {
    "id": "z1Za-5fOa-aS"
   },
   "outputs": [],
   "source": [
    "item_genres_one_hot = items[[\"item_id\", \"genres\"]].copy()\n",
    "item_genres_one_hot[\"genres\"] = item_genres_one_hot[\"genres\"].str.split(\", \")\n",
    "item_genres_one_hot = item_genres_one_hot.explode(\"genres\")\n",
    "item_genres_one_hot[\"genres\"] = item_genres_one_hot[\"genres\"].str.replace(\" \", \"_\")\n",
    "item_genres_one_hot[\"genres\"] = item_genres_one_hot[\"genres\"].map(lambda x: translit(x, \"ru\", reversed=True))\n",
    "item_genres_one_hot[\"value\"] = 1\n",
    "item_genres_one_hot = item_genres_one_hot.pivot(\n",
    "    index=\"item_id\",\n",
    "    columns=\"genres\",\n",
    "    values=\"value\"\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "item_genres_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t1JYcE_Qa-aS",
   "metadata": {
    "id": "t1JYcE_Qa-aS"
   },
   "outputs": [],
   "source": [
    "def get_hamming_distances(pairs: pd.Series, features: pd.DataFrame) -> np.ndarray:\n",
    "    items_0 = pairs.map(lambda pair: pair[1]).values\n",
    "    items_1 = pairs.map(lambda pair: pair[0]).values\n",
    "\n",
    "    features_0 = features.reindex(items_0).values\n",
    "    features_1 = features.reindex(items_1).values\n",
    "    return np.sum(features_0 != features_1, axis=1)\n",
    "\n",
    "\n",
    "def calculate_intra_list_diversity_per_user(recommendations: pd.DataFrame, features: pd.DataFrame) -> pd.Series:\n",
    "    recommended_item_pairs = recommendations.groupby(\"user_id\")[\"item_id\"].apply(\n",
    "        lambda x: list(combinations(x, 2))\n",
    "    ).reset_index().explode(\"item_id\").rename(columns={\"item_id\": \"item_pair\"})\n",
    "    recommended_item_pairs[\"dist\"] = get_hamming_distances(recommended_item_pairs[\"item_pair\"], features)\n",
    "    return recommended_item_pairs[[\"user_id\", \"dist\"]].groupby(\"user_id\").agg(\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YebBKjQ3a-aS",
   "metadata": {
    "id": "YebBKjQ3a-aS"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for model_name, recommendations in recommendations_dict.items():\n",
    "    ild_per_user = calculate_intra_list_diversity_per_user(recommendations, item_genres_one_hot)\n",
    "    print(f\"model: {model_name}, mean ild: {round(float(ild_per_user.mean()), 2)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Oc02mccoa-aT",
   "metadata": {
    "id": "Oc02mccoa-aT"
   },
   "source": [
    "Модель, тяготеющая к рекомендации популярного контента, отдает более разнообразные полки по набору жанров. Это логично, т.к. подборки популярного контента обычно разнообразны по значениям различных наборов признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dZOUPhpsa-aT",
   "metadata": {
    "id": "dZOUPhpsa-aT"
   },
   "source": [
    "## Mean Inverse User Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WY9NXnG9a-aT",
   "metadata": {
    "id": "WY9NXnG9a-aT"
   },
   "source": [
    "Оценим новизну рекомендаций. Новизна товара обратно пропорциональна количеству пользователей, которые с ним взаимодействовали в обучающей выборке. Значение метрики для полки определяется как средняя \"новизна\" товаров в полке.\n",
    "\n",
    "$$ MIUF = -\\frac{1}{|R|} \\sum_{i \\in R} \\log_2 \\frac{|U_i|}{|U|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rY-3td78a-aT",
   "metadata": {
    "id": "rY-3td78a-aT"
   },
   "outputs": [],
   "source": [
    "def calculate_mean_inv_user_frequency_per_user(recommendations: pd.DataFrame, train: pd.DataFrame) -> pd.Series:\n",
    "    n_users = train[\"user_id\"].nunique()\n",
    "    n_users_per_item = train.groupby(\"item_id\")[\"user_id\"].nunique()\n",
    "\n",
    "    recommendations_ = recommendations[[\"user_id\", \"item_id\"]].copy()\n",
    "    recommendations_[\"n_users_per_item\"] = recommendations_[\"item_id\"].map(n_users_per_item)\n",
    "    recommendations_[\"inv_user_freq\"] = -np.log2(recommendations_[\"n_users_per_item\"] / n_users)\n",
    "    return recommendations_[[\"user_id\", \"inv_user_freq\"]].groupby(\"user_id\").agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bP0aRh_a-aT",
   "metadata": {
    "id": "9bP0aRh_a-aT"
   },
   "outputs": [],
   "source": [
    "for model_name, recommendations in recommendations_dict.items():\n",
    "    miuf_per_user = calculate_mean_inv_user_frequency_per_user(recommendations, train)\n",
    "    print(f\"model: {model_name}, mean miuf: {round(float(miuf_per_user.mean()), 2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zvxMDFiSa-aU",
   "metadata": {
    "id": "zvxMDFiSa-aU"
   },
   "source": [
    "Естественно, модель, отдающая полки с популярным контентом, имеет значительно меньшее значение метрики, т.к. метрика принимает высокие значения в тех случаях, когда подборка состоит из контента в \"длинном\" хвосте."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
